# 个人学习笔记

## 1.HDFS

### 1.1 学习内容

#### 1.1.1 架构：

- Master（NameNode/NN）， 带 N 个 Slaves（DataNode/DN）
- 一个存储文件会被拆分成多个Block
  - blocksize：128M（hadoop 2.x版本默认）
  - 130M ==》 2个 Block 128M 和 2M
- NN：
  - 负责客户端请求的相应；
  - 负责存储元数据（文件的名称、副本系数、Block存放的DN）的管理
- DN
  - 存储用户的文件对应的数据块（Block）
  - 定期向NN发送心跳信息，汇报自身以及所有的Block信息，健康状况。
- replication factor：副本系数、副本因子。

#### 1.1.2 搭建Hadoop集群环境(三节点)

> **前置工作：**

- 准备三台虚拟机，这里使用VMWare创建三台Centos7的虚拟机；

| hostname | ip            |
| -------- | ------------- |
| node1    | 192.168.3.100 |
| node2    | 192.168.3.101 |
| node3    | 192.168.3.102 |

- 配置静态ip；
- 关闭防火墙；
- 关闭selinux安全级别，`/etc/selinux/config`中的`SELINUX=disabled`；
- 设置三台虚拟机的域名和IP的配置文件，`vi /etc/hosts`；
- 设置三台虚拟机免密登录-生成密钥以及分发密钥；
- 安装JDK；
- 时间同步：

```shell
#node1虚拟机作为时间主节点，下载ntp

yum install ntp -y

#修改配置文件，vi /etc/ntp.conf

restrict 192.168.254.0 mask 255.255.255.0 nomodify notrap

server 127.127.1.0(自己作为主节点，注释掉server开头的四行)

#启动ntp，并设置为开机启动

systemctl start ntpd

systemctl enable ntpd

#node2和node3作为从节点，下载ntpdate并同步数据

yum install ntpdate -y

ntpdate -u node1

#为了防止时间不一致，做定时器，定时同步node1时间数据,输出信息到空设备文件

crontab -e * * * * * /usr/sbin/ntpdate -u node1 >/dev/null 2>&1
```

- 安装Hadoop。

> **集群搭建：**

- 进到/usr/local/hadoop/etc/hadoop，修改hdfs-site.xml文件，在configuration标签里添加以下内容;

```xml
<!-- core-site.xml -->
<configuration>
    <!-- 在hdfs的地址名称:schame, ip, port -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node1:8020</value>
    </property>
    <!-- hdfs的一个基础路径，被其他属性所依赖的一个基础路径 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/root/app/hadoop/tmp</value>
    </property>
</configuration>
```

```xml
<!-- hdfs-site.xml -->
<configuration>
    <!-- namenode守护进程管理的元数据文件fsimage存储的位置-->
    <property>
    <name>dfs.namenode.name.dir</name>
    <value>file://${hadoop.tmp.dir}/dfs/name</value>
    </property>
    <!-- 确定DFS数据节点应该将其块存储在本地文件系统的何处-->
    <property>
    <name>dfs.datanode.data.dir</name>
    <value>file://${hadoop.tmp.dir}/dfs/data</value>
    </property>
    <!-- 块的副本数-->
    <property>
    <name>dfs.replication</name>
        <value>3</value>
    </property>
    <!-- 块的大小(128M)，下面的单位是字节-->
    <property>
        <name>dfs.blocksize</name>
        <value>134217728</value>
    </property>
    <!-- secondarynamenode守护进程的http地址:主机名和端口号。参考守护进程布局-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node2:50090</value>
    </property>
    <!-- namenode守护进程的http地址:主机名和端口号。参考守护进程布局-->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>node1:50070 </value>
    </property>
</configuration>
```

- 在mapred-site.xml文件configuration标签里添加以下内容-这里不存在mapred-site.xml文件，需要将mapred-site.xml.template文件复制后重命名；

```xml
<!-- mapred-site.xml -->
<configuration>
    <!-- 指定mapreduce使用yarn资源管理器-->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property><!-- 配置作业历史服务器的地址-->
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>node1:10020</value></property>
    <!--配置作业历史服务器的http地址-->
    <property>
        <name>mapreduce.jobhistory.webappaddress</name>
        <value>node1:19888</value>
    </property>
</configuration>
```

- 在yarn-site.xml文件configuration标签里添加以下内容；

```xml
<!-- yarn-site.xml -->
<configuration>
    <!-- 指定yarn的shuffle技术-->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- 指定resourcemanager的主机名-->
    <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>node1</value>
    </property>
    <!--下面的可选-->
    <!--指定shuffle对应的类 -->
    <property>
    <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <!--配置resourcemanager的内部通讯地址-->
    <property>
        <name>yarn.resourcemanager.address</name>
        <value>node1:8032</value>
    </property>
    <!--配置resourcemanager的scheduler的内部通讯地址-->
    <property>
        <name>yarn,resourcemanager.scheduler.address</name>
        <value>node1:8030</value>
    </property>
    <!--配置resoucemanager的资源调度的内部通讯地址-->
    <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>node1:8031</value>
    </property>
    <!--配置resourcemanager的管理员的内部通讯地址-->
    <property>
        <name>yarn.resourcemanager.admin.address</name>
        <value>node1:8033</value>
    </property>
    <!--配置resourcemanager的web ui 的监控页面-->
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>node1:8088</value>
    </property>
</configuration>
```

- 在hadoop-env.sh文件修改JDK安装路径；
- 在yarn-env.sh文件修改JDK安装路径；
- 在slaves文件中添加虚拟机名称
- 启动集群：

```shell
/root/app/hadoop/sbin/start-all.sh
```

- jps指令查看进程启动情况

```tex
# node1

2192 NodeManager
1489 DataNode
2503 Jps
2090 ResourceManager
```

```tex
# node2

1888 Jps
1305 DataNode
1769 NodeManager
```

#### 1.1.3 java api操作远端hdfs目录

- 创建maven工程，导入依赖：

```xml
<properties>
    <maven.compiler.source>8</maven.compiler.source>
    <maven.compiler.target>8</maven.compiler.target>
    <hadoop.version>2.10.2</hadoop.version>
</properties>

<dependencies>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-common</artifactId>
        <version>${hadoop.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-hdfs</artifactId>
        <version>${hadoop.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-client</artifactId>
        <version>${hadoop.version}</version>
    </dependency>
    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>4.13.2</version>
        <scope>compile</scope>
    </dependency>
</dependencies>
```

- 测试api的前置工作-创建好连接，类似于jdbc的连接：

```java
FileSystem fs = null;

@Before
public void init() throws IOException {
    // 1.构建一个配置参数对象，设置一个参数，即我们需要访问的hdfs的URI
    Configuration conf = new Configuration();
    // 2.这里指定使用的是hdfs文件系统
    conf.set("fs.defaultFS", "hdfs://node1:8020");
    // 3.通过如下的方式进行客户端身份的设置
    System.setProperty("HADOOP_USER_NAME", "root");
    // 4.通过FileSystem的静态方法获取文件系统客户端对象
    fs = FileSystem.get(conf);
}
```

- 测试java c-r-u-d

```java
/**
     * 向hdfs集群添加文件
     * @throws IOException io异常抛出
     */
@Test
public void testAddFileToHdfs() throws IOException {
    // 1.要上传文件的本地目录
    Path src = new Path("D:/test.txt");
    // 2.要上传到hdfs的目标路径
    Path dst = new Path("/data");
    // 3.上传操作
    fs.copyFromLocalFile(src, dst);
    // 4.关闭资源
    fs.close();
}

/**
     * 删除hdfs集群目录或文件
     * @throws IOException io异常
     */
@Test
public void testDeleteFileFromHdfs() throws IOException {
    Path path = new Path("/a");
    fs.delete(path, true);
}

/**
     * 创建目录或重命名文件/目录
     * @throws IOException io异常
     */
@Test
public void testMkdirOrRenameToHdfs() throws IOException {
    fs.mkdirs(new Path("/a/b/c"));
    fs.mkdirs(new Path("/a1/b1/c1"));
    fs.rename(new Path("/a"), new Path("/a3"));
}

/**
     * 获取文件列表
     * @throws IOException io异常
     */
@Test
public void testGetFileList() throws IOException {
    // 1.过去迭代器对象
    RemoteIterator<LocatedFileStatus> listFiles = fs.listFiles(new Path("/"), true);
    while (listFiles.hasNext()) {
        LocatedFileStatus fileStatus = listFiles.next();
        // 文件名
        System.out.println(fileStatus.getPath().getName());
        // 文件块大小
        System.out.println(fileStatus.getBlockSize());
        // 文件权限
        System.out.println(fileStatus.getPermission());
        // 文件内容权限
        System.out.println(fileStatus.getLen());
        // 文件块信息
        BlockLocation[] blockLocations = fileStatus.getBlockLocations();
        for (BlockLocation bl : blockLocations) {
            System.out.println("bl - len: " + bl.getLength()
                               + "--"
                               + "bl - offset" + bl.getOffset());
            String[] hosts = bl.getHosts();
            for (String host : hosts) {
                System.out.println(host);
            }
        }
    }
}
```

